{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning in Keras\n",
    "\n",
    "In this notebook, we will implement transfer learning in Python using the pre-trained ResNet model. We will run two experiments - 1. **Freezing the base model weights**, adding a few layers to it at the end (fully connected etc.) and training the newly added layers, and 2. **Freezing the first 140 layers of ResNet** and retraining the rest.\n",
    "\n",
    "Apart from this, you will learn **two important practical preprocessing techniques** in this notebook - **data augmentation** and **data generators**. The notebook is dividede into the following sections:\n",
    "1. Importing libraries\n",
    "2. Splitting into train and test set\n",
    "3. Importing the pretrained ResNet model\n",
    "4. Data Generators: Preprocessing and Generating Batch-Wise Data (On the Fly)\n",
    "5. Training the Base Model (Using Batch-Wise Data Generation)\n",
    "6. Freezing the initial-n layers and training the rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For downloading the dataset\n",
    "# Go to Kaggle.com -> My Account -> Create new API Token -> Upload kaggle.json in Jupyter Home\n",
    "!mkdir ~/.kaggle\n",
    "!cp ../kaggle.json ~/.kaggle/kaggle.json\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle config set -n proxy -v http://10.140.0.96:3128\n",
    "!kaggle datasets download -d alxmamaev/flowers-recognition\n",
    "!unzip flowers-recognition.zip\n",
    "!rm flowers-recognition.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import glob   \n",
    "import keras.backend as K\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
    "import scipy.misc\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# for reading images\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "# channels last is the format used by tensorflow \n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Into Train and Test\n",
    "\n",
    "Let's now split the data into train and test directories. Firstly, note that the most common way to organize (images) data is to create two/three directories - train and test (or validation) having n-subdirectories, each subdirectory being a class (here, five subdirs for the five flower types).\n",
    "\n",
    "The following function creates two directories - train and test, each having five subdirectories (sunflower, dandelion, rose, tulip, daisy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to where the 'flowers' directory is located\n",
    "data_dir = 'flowers'\n",
    "\n",
    "# Training data dir\n",
    "training_dir = 'Train'\n",
    "\n",
    "# Test data dir\n",
    "testing_dir = 'Test'\n",
    "\n",
    "# Ratio of training and testing data\n",
    "train_test_ratio = 0.8 \n",
    "\n",
    "\n",
    "def split_dataset_into_test_and_train_sets(all_data_dir = data_dir, training_data_dir = training_dir, testing_data_dir=testing_dir, train_test_ratio = 0.8):\n",
    "\n",
    "    # recreate test and train directories if they don't exist\n",
    "    if not os.path.exists(training_data_dir):\n",
    "        os.mkdir(training_data_dir)\n",
    "\n",
    "    if not os.path.exists(testing_data_dir):\n",
    "        os.mkdir(testing_data_dir)               \n",
    "    \n",
    "    num_training_files = 0\n",
    "    num_testing_files = 0\n",
    "\n",
    "    # iterate through the data directory \n",
    "    for subdir, dirs, files in os.walk(all_data_dir):\n",
    "        \n",
    "        category_name = os.path.basename(subdir)\n",
    "\n",
    "        if category_name == os.path.basename(all_data_dir):\n",
    "            continue\n",
    "\n",
    "        training_data_category_dir = training_data_dir + '/' + category_name\n",
    "        testing_data_category_dir = testing_data_dir + '/' + category_name\n",
    "        \n",
    "        # creating subdirectory for each sub category\n",
    "        if not os.path.exists(training_data_category_dir):\n",
    "            os.mkdir(training_data_category_dir)   \n",
    "\n",
    "        if not os.path.exists(testing_data_category_dir):\n",
    "            os.mkdir(testing_data_category_dir)\n",
    "            \n",
    "        file_list = glob.glob(subdir + '/*.jpg')\n",
    "\n",
    "        print(str(category_name) + ' has ' + str(len(files)) + ' images') \n",
    "        random_set = np.random.permutation((file_list))\n",
    "        \n",
    "        # copy percentage of data from each category to train and test directory\n",
    "        train_list = random_set[:round(len(random_set)*(train_test_ratio))] \n",
    "        test_list = random_set[-round(len(random_set)*(1-train_test_ratio)):]\n",
    "        \n",
    "        for lists in train_list : \n",
    "            shutil.copy(lists, training_data_dir + '/' + category_name + '/' )\n",
    "            num_training_files += 1\n",
    "  \n",
    "        for lists in test_list : \n",
    "            shutil.copy(lists, testing_data_dir + '/' + category_name + '/' )\n",
    "            num_testing_files += 1\n",
    "  \n",
    "\n",
    "    print(\"Processed \" + str(num_training_files) + \" training files.\")\n",
    "    print(\"Processed \" + str(num_testing_files) + \" testing files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split into train and test directories\n",
    "split_dataset_into_test_and_train_sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Pre-Trained Model \n",
    "\n",
    "Let's now import the pretrained ResNet model. In the first experiment, we will use the pretrained weights (from Imagenet) of ResNet. The argument `include_top = False` specifies that we do not want to import the top layers (the last ones, which are typically pooling, FC, softmax etc.). We'll add some of our own last layers (a global average poooling layer and a final softmax) and train just those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of classes \n",
    "num_classes = 5\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    # Get base model: ResNet50 \n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "    \n",
    "    # freeze the layers in base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Get the output from the base model \n",
    "    base_model_ouput = base_model.output\n",
    "    \n",
    "    # Adding our own layers at the end\n",
    "    # global average pooling: computes the average of all values in the feature map\n",
    "    x = GlobalAveragePooling2D()(base_model_ouput)\n",
    "    \n",
    "    # fully connected and 5-softmax layer\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax', name='fcnew')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the model\n",
    "model = get_model()\n",
    "\n",
    "# compile it\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the total number of parameters in the model is about 24 million, though the number of trainable parameters is only about 1 million.\n",
    "\n",
    "Let's now see how we'll feed the data to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generators: Preprocessing and Generating Batch-Wise Data (On the Fly)\n",
    "\n",
    "We will now implement an incredibly useful preprocessing technique - **data augmentation** using **data generators**.\n",
    "\n",
    "You will learn preprocessing techniques in detail in the next industry session, though they're quire easy to understand anyway. Here's a quick overview.\n",
    "\n",
    "**Data Augmentation** is a commonly used technique in image processing used to 'create' more training data. It basically modifies the original training images a bit (e.g. rotates them by a few degrees, changes the colour shades a little, etc.) to 'create' (or augment) new training images. The basic reason to do this is to **increase the amount of variance** in the training data. It is possible to do this with images because if you rotate the image of (say) a dog (or change the colours a bit, stretch the image horizontally etc.), it stays a dog. Thus, you can create many images from each training image while the label stays the same.\n",
    "\n",
    "In the code below, we have specified the augmentation techniques as `shear_range=0.2, zoom_range=0.2, horizontal_flip=True`. Shear 'stretches' the images, zoom_range zooms them in, and horizontal_flip 'flips' them around horizontally.\n",
    "\n",
    "Now, in the code below, you will notice that we have something called `ImageDataGenerator` - lets understand what it does.\n",
    "\n",
    "**Data generators** are used to **feed data points in batches** to the model. The main reason to use them is that they are efficient (compared to feeding one data point at a time, or all of them at once which will require a lot of memory). What's cooler about them is that they (at least in keras) can preprocess the images and create augmented ones *on the fly*, i.e. as the batches are fed to the model, the augmented images are created and preprocessed. This eliminates the need to store the augmented images separately.\n",
    "\n",
    "An important point to note is that you **never augment the validation or test sets**, only the training set. This is because test (and validation) sets are supposed to be representative of the real images you'll get in the real world. However, you do apply basic preprocessing to validation and test sets (scaling/centering them etc.).\n",
    "\n",
    "In the code below, the method `flow_from_directory` 'flows' the data in batches from the training and test directories. It is an instance of `ImageDataGenerator` where we specify the preprocessing and augmentation techniques that we want to use. In this case, we are just using the standard preprocessing techniques that come with the `preprocess_input` module in keras.\n",
    "\n",
    "You can <a href=\"https://keras.io/preprocessing/image/\">read about data generators here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using ImageDataGenerator for pre-processing\n",
    "\n",
    "image_size = 224\n",
    "batch_size = 64\n",
    "\n",
    "# help(ImageDataGenerator)\n",
    "train_data_gen = ImageDataGenerator(preprocessing_function = preprocess_input, \n",
    "                                    shear_range=0.2, zoom_range=0.2, \n",
    "                                    horizontal_flip=True)\n",
    "\n",
    "# do only basic preprocessing for validation data (no data augmentation)\n",
    "valid_data_gen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "# create data generator objects\n",
    "train_generator = train_data_gen.flow_from_directory(training_dir, (image_size,image_size), batch_size=batch_size, class_mode='categorical')\n",
    "valid_generator = valid_data_gen.flow_from_directory(testing_dir, (image_size,image_size), batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the number of training and validation images is increased (because of data augmentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Base Model (Using Batch-Wise Data Generation)\n",
    "\n",
    "Let's now train the model. When we use data generators, we use the `model.fit_generator` method rather than the usual `model.fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training the newly added layers \n",
    "epochs = 5\n",
    "\n",
    "# flow data (in batches) from directories (while simultaneously preprocessing/augmenting\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n//batch_size,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.n//batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing the Initial-n Layers and Training the Rest\n",
    "\n",
    "Let's now try another variant of transfer learning. We will freeze the first 140 layers of ResNet (with the hypopthesis that they have learnt to extract some useful generic features from their ImageNet experience) and train the rest of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "# training the model after 140 layers\n",
    "split_at = 140\n",
    "for layer in model.layers[:split_at]: layer.trainable = False\n",
    "for layer in model.layers[split_at:]: layer.trainable = True\n",
    "    \n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Choosing lower learning rate for fine-tuning\n",
    "# learning rate is generally 10-1000 times lower than normal learning rate when we are fine tuning the initial layers\n",
    "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n//batch_size,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.n//batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
